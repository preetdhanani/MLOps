# ğŸ§  MLOps: Industry-Ready Machine Learning Pipeline with MLflow

This project demonstrates an **end-to-end MLOps architecture**, designed to mimic how machine learning pipelines are built and managed in real-world production environments. Developed as part of my Masterâ€™s in Artificial Intelligence & Robotics, this repository focuses on modular design, reproducibility, experiment tracking, and automation.

---

## ğŸš€ Project Goals

- Simulate an **industry-standard MLOps pipeline**
- Apply modular development from data to model evaluation
- Use **MLflow** for experiment tracking
- Implement **CI/CD workflows** using GitHub Actions
- Prepare for deployment and scaling (deployment not included due to financial constraints)

---

## ğŸ§± Project Structure

```bash
MLOps/
â”œâ”€â”€ .github/workflows/       # GitHub Actions workflow
â”œâ”€â”€ artifacts/               # Intermediate data and model files
â”‚   â””â”€â”€ [data_ingestion, transformation, evaluation...]
â”œâ”€â”€ config/                  # YAML configuration
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ mlruns/                  # MLflow tracking data
â”œâ”€â”€ src/
â”‚   â””â”€â”€ mlProject/
â”‚       â”œâ”€â”€ components/      # Core modules: ingestion, transformation, trainer
â”‚       â”œâ”€â”€ pipeline/        # Stage-wise pipeline execution scripts
â”‚       â”œâ”€â”€ config/          # Project-level config and schema
â”‚       â””â”€â”€ utils/           # Utility functions
â”œâ”€â”€ templates/               # HTML templates for Flask app
â”œâ”€â”€ Dockerfile               # Container setup (optional)
â”œâ”€â”€ app.py                   # Flask web app (prediction UI)
â”œâ”€â”€ params.yaml              # Parameter configuration
â”œâ”€â”€ requirements.txt         # Project dependencies
â”œâ”€â”€ schema.yaml              # Data schema definition
â””â”€â”€ README.md


```

## ğŸ”„ Pipeline Overview

Each pipeline stage is modular and traceable:

1. **Data Ingestion**  
   Reads raw data and stores it for processing.

2. **Data Validation**  
   Ensures the input data adheres to the expected schema.

3. **Data Transformation**  
   Handles missing values, encodes features, and scales the data.

4. **Model Training**  
   Trains the ML model and logs metrics using MLflow.

5. **Model Evaluation**  
   Compares predictions and evaluates the model using predefined metrics.

---

## ğŸ› ï¸ Technologies Used

- **Python** â€“ Core language
- **MLflow** â€“ Experiment tracking
- **PyYAML** â€“ Configuration management
- **Flask** â€“ Simple web app for inference
- **GitHub Actions** â€“ Automating workflows
- **Docker** â€“ Containerization (optional)

---

## âš™ï¸ Getting Started

### ğŸ”§ Installation

```bash
git clone https://github.com/preetdhanani/MLOps.git
cd MLOps
python -m venv venv
source venv/bin/activate  # or use venv\Scripts\activate on Windows
pip install -r requirements.txt
